# 🖐️ Real-Time Sign Language Recognition Using YOLOv8
![image](https://github.com/user-attachments/assets/674a07cd-259f-48a4-afc3-b396ce7218f5)

## 📌 Overview
This project implements **real-time** American Sign Language (ASL) **letter recognition (A-Z)** using **YOLOv8**. It detects hand signs from webcam input and predicts the corresponding letter with high accuracy.

## 🚀 Features
+ ✅ Real-time sign language letter detection
+ ✅ Trained YOLOv8 model for precise predictions
+ ✅ Works with live webcam feed
+ ✅ Optimized for efficiency and speed

## 📂 Dataset
The model is trained on a dataset containing 26 hand gestures Images, each corresponding to a letter from A to Z. The dataset includes labeled images of hands forming these letters.

## 🖥️ Usage
+ The script will open a webcam feed.
+ Make a hand gesture corresponding to a sign language letter.
+ The detected letter will be displayed on the screen.
+ Press 'q' to exit.

## 📷 Sample Output

![image](https://github.com/user-attachments/assets/d4dc58ff-d801-45ca-a6c6-487adc95f755)


https://github.com/user-attachments/assets/2e69ebe3-f001-44c3-a326-6a553860879c


## 🔥 Future Improvements
+ Enhance model accuracy with more diverse hand gesture images.
+ Add support for full sign language words instead of just letters.
+ Deploy as a web or mobile application for wider accessibility.

## 👨‍💻 Author
Siddharth Jaiswal

## 📜 License
This project is licensed under the MIT License.
